{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ad7ad4092b48318ad01552defc9027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ardav\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ardav\\.cache\\huggingface\\hub\\models--indobenchmark--indobert-base-p1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45536e8893a45aeb2da27807461265c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4bd7c578e5497c9203d919dfd29500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5017e27ebd5b4bf6b5a72ce902bf78d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755b20ee3609485bacc7a33aee373e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# load indobert model as the encoder\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "encoder = BertModel.from_pretrained('indobenchmark/indobert-base-p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7677d16b2f644b01a47f3c379aa79e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ardav\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ardav\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cb8431704648eebd7f978d68f9d86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1a12c1285c43b784460cf103ccbc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370b437fb8dd48d5aa58a8a7ca2c4fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd87dff81e746b6bf3800d7010a3631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aceafd12582e421ba5e1f547cec74869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f70ca8a8b964e8da79600d15db9e692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "# load GPT-2 as the decoder\n",
    "decoder_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "decoder = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import EncoderDecoderModel, GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "gpt2_config = GPT2Config.from_pretrained('gpt2')\n",
    "gpt2_config.add_cross_attention = True\n",
    "\n",
    "decoder = GPT2LMHeadModel.from_pretrained('gpt2', config=gpt2_config)\n",
    "\n",
    "# Initialize the Encoder-Decoder Model\n",
    "model = EncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
    "\n",
    "# Define tokenizers for both encoder and decoder\n",
    "model.config.decoder_start_token_id = decoder_tokenizer.bos_token_id\n",
    "model.config.pad_token_id = decoder_tokenizer.pad_token_id\n",
    "model.config.eos_token_id = decoder_tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Indonesian text\n",
    "input_text = \"\"\"\n",
    "Bandung, 5 Juli 2024 --- Kebutaan akan membawa dampak negatif bagi penderitanya. Pentingnya menjaga Kesehatan mata untuk mencegah kebutaan membuat sekelompok mahasiswa dari Fakultas Informatika Telkom University menciptakan inovasi untuk mengidentifikasi penyakit mata.\n",
    "Inovasi ini diberi nama OptiGuard yang dikembangkan melalui Program Kreativitas Mahasiswa Bidang Karsa Cipta (PKM-KC) dan berhasil mendapatkan pendanaan dari Kemendikbudristek. OptiGuard diciptakan sebagai upaya preventif mencegah kebutaan dengan mendeteksi dini penyakit mata, sehingga penyakit mata dapat ditangani sebelum semakin parah dan memperkecil peluang terjadinya kebutaan. Inovasi OptiGuard ini mengedepakan efisiensi, kecepatan, dan ketepatan dalam mendiagnosis penyakit mata.\n",
    "OptiGuard merupakan hasil kolaborasi dari sekelompok mahasiswa program studi S1 Sains Data Telkom University yang memiliki peranannya masing-masing. Hendrik Mario Ignatius sebagai Koordinator dan Front End Developer, Izzulhaq Mahardika sebagai Adaptor designer dan Back End Developer, Nida Anggraeni sebagai Reseacher dan Public Relation, Nadia Nurhalija Zuaeni sebagai Content Creator dan Researcher, dan Tiara Sabrina sebagai AI Engineer dan UI/UX Designer. Pengembangan inovasi ini rutin dipantau dan didampingi oleh Dr. Gamma Kosala, S.Si.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize input text for IndoBERT with max_length\n",
    "encoder_input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).input_ids\n",
    "\n",
    "# Prepare decoder input for GPT-2 with max_length\n",
    "decoder_input_ids = decoder_tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=50).input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ardav\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids, labels=decoder_input_ids)\n",
    "loss = outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: \"I'm not going to lie to you. I'm not going to lie to you. I'm not going to lie to you. I'm not going to lie to you. I'm not going to lie to you. I'm not\n"
     ]
    }
   ],
   "source": [
    "# Generate summary\n",
    "generated_ids = model.generate(encoder_input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
    "summary = decoder_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning using Indosum Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'id', 'summary'],\n",
       "        num_rows: 14262\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'id', 'summary'],\n",
       "        num_rows: 3762\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'id', 'summary'],\n",
       "        num_rows: 750\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indosum = load_dataset('maryantocinn/indosum', trust_remote_code=True)\n",
    "indosum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6240d8904fa04153be15a88927a44a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b956d252feb4ff4974f0dc4db3ccc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3762 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9b459cb4de48e5bcce6bf4e5b48f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, GPT2Tokenizer\n",
    "\n",
    "# Load tokenizers for IndoBERT and GPT-2\n",
    "encoder_tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "decoder_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Ensure GPT-2 has a pad token\n",
    "decoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n",
    "\n",
    "# Preprocessing function for tokenizing inputs and labels\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the input (Indonesian text) for IndoBERT (encoder)\n",
    "    inputs = encoder_tokenizer(examples['document'], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "    # Tokenize the summary (Indonesian summary) for GPT-2 (decoder)\n",
    "    labels = decoder_tokenizer(examples['summary'], padding='max_length', truncation=True, max_length=50, return_tensors='pt')\n",
    "\n",
    "    # Return tokenized inputs and labels\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs\n",
    "\n",
    "# Apply the preprocessing to the dataset\n",
    "tokenized_dataset = indosum.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import EncoderDecoderModel, GPT2Config, BertModel, GPT2LMHeadModel\n",
    "\n",
    "# Load IndoBERT as encoder\n",
    "encoder = BertModel.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "\n",
    "# Load GPT-2 with cross-attention enabled as decoder\n",
    "gpt2_config = GPT2Config.from_pretrained('gpt2')\n",
    "gpt2_config.add_cross_attention = True\n",
    "decoder = GPT2LMHeadModel.from_pretrained('gpt2', config=gpt2_config)\n",
    "\n",
    "# Create encoder-decoder model\n",
    "model = EncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
    "\n",
    "# Set decoder-specific tokens\n",
    "model.config.decoder_start_token_id = decoder_tokenizer.bos_token_id\n",
    "model.config.pad_token_id = decoder_tokenizer.pad_token_id\n",
    "model.config.eos_token_id = decoder_tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2SdpaAttention(\n",
       "            (c_attn): Conv1D(nf=2304, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=768)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): GPT2SdpaAttention(\n",
       "            (c_attn): Conv1D(nf=1536, nx=768)\n",
       "            (q_attn): Conv1D(nf=768, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=768)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=3072, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=3072)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Move model to the device (GPU)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdfa7c7c8914447855a86aa83e07d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.3072, 'grad_norm': 14.094103813171387, 'learning_rate': 1.9986913441764818e-05, 'epoch': 0.0}\n",
      "{'loss': 7.0322, 'grad_norm': 16.14720344543457, 'learning_rate': 1.99682183585717e-05, 'epoch': 0.01}\n",
      "{'loss': 6.9353, 'grad_norm': 15.281745910644531, 'learning_rate': 1.994952327537858e-05, 'epoch': 0.01}\n",
      "{'loss': 6.8332, 'grad_norm': 14.970441818237305, 'learning_rate': 1.9930828192185456e-05, 'epoch': 0.01}\n",
      "{'loss': 6.6021, 'grad_norm': 16.943391799926758, 'learning_rate': 1.9912133108992336e-05, 'epoch': 0.01}\n",
      "{'loss': 6.4949, 'grad_norm': 16.08842658996582, 'learning_rate': 1.9893438025799216e-05, 'epoch': 0.02}\n",
      "{'loss': 6.5791, 'grad_norm': 16.89444923400879, 'learning_rate': 1.9874742942606097e-05, 'epoch': 0.02}\n",
      "{'loss': 6.4611, 'grad_norm': 17.838171005249023, 'learning_rate': 1.9856047859412977e-05, 'epoch': 0.02}\n",
      "{'loss': 6.4142, 'grad_norm': 17.44211769104004, 'learning_rate': 1.9837352776219857e-05, 'epoch': 0.03}\n",
      "{'loss': 6.2693, 'grad_norm': 18.627887725830078, 'learning_rate': 1.9818657693026734e-05, 'epoch': 0.03}\n",
      "{'loss': 6.2702, 'grad_norm': 20.256505966186523, 'learning_rate': 1.9799962609833615e-05, 'epoch': 0.03}\n",
      "{'loss': 6.1105, 'grad_norm': 19.89427375793457, 'learning_rate': 1.9781267526640495e-05, 'epoch': 0.03}\n",
      "{'loss': 6.2077, 'grad_norm': 20.61543846130371, 'learning_rate': 1.9762572443447375e-05, 'epoch': 0.04}\n",
      "{'loss': 6.11, 'grad_norm': 22.728317260742188, 'learning_rate': 1.9743877360254256e-05, 'epoch': 0.04}\n",
      "{'loss': 5.9717, 'grad_norm': 21.61443328857422, 'learning_rate': 1.9725182277061136e-05, 'epoch': 0.04}\n",
      "{'loss': 6.0624, 'grad_norm': 19.819660186767578, 'learning_rate': 1.9706487193868013e-05, 'epoch': 0.04}\n",
      "{'loss': 5.929, 'grad_norm': 23.11989402770996, 'learning_rate': 1.9687792110674893e-05, 'epoch': 0.05}\n",
      "{'loss': 5.9501, 'grad_norm': 20.713848114013672, 'learning_rate': 1.9669097027481773e-05, 'epoch': 0.05}\n",
      "{'loss': 5.8252, 'grad_norm': 21.57269287109375, 'learning_rate': 1.9650401944288654e-05, 'epoch': 0.05}\n",
      "{'loss': 5.8411, 'grad_norm': 21.811756134033203, 'learning_rate': 1.9631706861095534e-05, 'epoch': 0.06}\n",
      "{'loss': 5.7772, 'grad_norm': 22.953105926513672, 'learning_rate': 1.9613011777902414e-05, 'epoch': 0.06}\n",
      "{'loss': 5.7236, 'grad_norm': 23.247337341308594, 'learning_rate': 1.959431669470929e-05, 'epoch': 0.06}\n",
      "{'loss': 5.748, 'grad_norm': 21.60177993774414, 'learning_rate': 1.9575621611516175e-05, 'epoch': 0.06}\n",
      "{'loss': 5.7012, 'grad_norm': 20.69042205810547, 'learning_rate': 1.9556926528323052e-05, 'epoch': 0.07}\n",
      "{'loss': 5.6247, 'grad_norm': 21.730422973632812, 'learning_rate': 1.9538231445129932e-05, 'epoch': 0.07}\n",
      "{'loss': 5.7184, 'grad_norm': 20.095050811767578, 'learning_rate': 1.9519536361936813e-05, 'epoch': 0.07}\n",
      "{'loss': 5.6478, 'grad_norm': 22.325918197631836, 'learning_rate': 1.9500841278743693e-05, 'epoch': 0.08}\n",
      "{'loss': 5.7079, 'grad_norm': 19.347654342651367, 'learning_rate': 1.948214619555057e-05, 'epoch': 0.08}\n",
      "{'loss': 5.5494, 'grad_norm': 20.94718360900879, 'learning_rate': 1.9463451112357454e-05, 'epoch': 0.08}\n",
      "{'loss': 5.7663, 'grad_norm': 22.638513565063477, 'learning_rate': 1.944475602916433e-05, 'epoch': 0.08}\n",
      "{'loss': 5.6922, 'grad_norm': 22.19648551940918, 'learning_rate': 1.942606094597121e-05, 'epoch': 0.09}\n",
      "{'loss': 5.4659, 'grad_norm': 21.870853424072266, 'learning_rate': 1.940736586277809e-05, 'epoch': 0.09}\n",
      "{'loss': 5.5108, 'grad_norm': 21.8524227142334, 'learning_rate': 1.9390540287904282e-05, 'epoch': 0.09}\n",
      "{'loss': 5.517, 'grad_norm': 21.010601043701172, 'learning_rate': 1.9371845204711163e-05, 'epoch': 0.1}\n",
      "{'loss': 5.4294, 'grad_norm': 20.65683937072754, 'learning_rate': 1.9353150121518043e-05, 'epoch': 0.1}\n",
      "{'loss': 5.3777, 'grad_norm': 22.09243392944336, 'learning_rate': 1.9334455038324923e-05, 'epoch': 0.1}\n",
      "{'loss': 5.3938, 'grad_norm': 21.512714385986328, 'learning_rate': 1.93157599551318e-05, 'epoch': 0.1}\n",
      "{'loss': 5.3992, 'grad_norm': 21.852394104003906, 'learning_rate': 1.929706487193868e-05, 'epoch': 0.11}\n",
      "{'loss': 5.4198, 'grad_norm': 19.79967498779297, 'learning_rate': 1.927836978874556e-05, 'epoch': 0.11}\n",
      "{'loss': 5.504, 'grad_norm': 21.281150817871094, 'learning_rate': 1.925967470555244e-05, 'epoch': 0.11}\n",
      "{'loss': 5.1843, 'grad_norm': 20.750722885131836, 'learning_rate': 1.924097962235932e-05, 'epoch': 0.11}\n",
      "{'loss': 5.2717, 'grad_norm': 20.627580642700195, 'learning_rate': 1.9222284539166202e-05, 'epoch': 0.12}\n",
      "{'loss': 5.2778, 'grad_norm': 21.295522689819336, 'learning_rate': 1.920358945597308e-05, 'epoch': 0.12}\n",
      "{'loss': 5.1688, 'grad_norm': 20.43625831604004, 'learning_rate': 1.918489437277996e-05, 'epoch': 0.12}\n",
      "{'loss': 5.3076, 'grad_norm': 21.14314842224121, 'learning_rate': 1.916619928958684e-05, 'epoch': 0.13}\n",
      "{'loss': 5.1817, 'grad_norm': 19.225801467895508, 'learning_rate': 1.914750420639372e-05, 'epoch': 0.13}\n",
      "{'loss': 5.1765, 'grad_norm': 20.19355583190918, 'learning_rate': 1.91288091232006e-05, 'epoch': 0.13}\n",
      "{'loss': 5.1564, 'grad_norm': 19.376848220825195, 'learning_rate': 1.911011404000748e-05, 'epoch': 0.13}\n",
      "{'loss': 5.2098, 'grad_norm': 19.891559600830078, 'learning_rate': 1.909141895681436e-05, 'epoch': 0.14}\n",
      "{'loss': 5.1338, 'grad_norm': 19.001537322998047, 'learning_rate': 1.907272387362124e-05, 'epoch': 0.14}\n",
      "{'loss': 5.1259, 'grad_norm': 18.512062072753906, 'learning_rate': 1.9054028790428118e-05, 'epoch': 0.14}\n",
      "{'loss': 5.0674, 'grad_norm': 18.90645408630371, 'learning_rate': 1.9035333707235e-05, 'epoch': 0.15}\n",
      "{'loss': 5.0962, 'grad_norm': 19.964397430419922, 'learning_rate': 1.901663862404188e-05, 'epoch': 0.15}\n",
      "{'loss': 5.0331, 'grad_norm': 18.645122528076172, 'learning_rate': 1.899794354084876e-05, 'epoch': 0.15}\n",
      "{'loss': 5.0564, 'grad_norm': 19.840194702148438, 'learning_rate': 1.897924845765564e-05, 'epoch': 0.15}\n",
      "{'loss': 4.9722, 'grad_norm': 20.95248794555664, 'learning_rate': 1.896055337446252e-05, 'epoch': 0.16}\n",
      "{'loss': 4.931, 'grad_norm': 19.033769607543945, 'learning_rate': 1.8941858291269397e-05, 'epoch': 0.16}\n",
      "{'loss': 4.9083, 'grad_norm': 18.352075576782227, 'learning_rate': 1.8923163208076277e-05, 'epoch': 0.16}\n",
      "{'loss': 4.8339, 'grad_norm': 20.609386444091797, 'learning_rate': 1.8904468124883157e-05, 'epoch': 0.17}\n",
      "{'loss': 5.0322, 'grad_norm': 17.788169860839844, 'learning_rate': 1.8885773041690038e-05, 'epoch': 0.17}\n",
      "{'loss': 4.9406, 'grad_norm': 19.1134090423584, 'learning_rate': 1.8867077958496918e-05, 'epoch': 0.17}\n",
      "{'loss': 4.9538, 'grad_norm': 21.066692352294922, 'learning_rate': 1.8848382875303798e-05, 'epoch': 0.17}\n",
      "{'loss': 4.9901, 'grad_norm': 19.46894645690918, 'learning_rate': 1.8829687792110675e-05, 'epoch': 0.18}\n",
      "{'loss': 4.9692, 'grad_norm': 17.895891189575195, 'learning_rate': 1.8810992708917555e-05, 'epoch': 0.18}\n",
      "{'loss': 4.9733, 'grad_norm': 18.337318420410156, 'learning_rate': 1.8792297625724436e-05, 'epoch': 0.18}\n",
      "{'loss': 4.9953, 'grad_norm': 16.833158493041992, 'learning_rate': 1.8773602542531316e-05, 'epoch': 0.19}\n",
      "{'loss': 4.9611, 'grad_norm': 18.51122283935547, 'learning_rate': 1.8754907459338196e-05, 'epoch': 0.19}\n",
      "{'loss': 4.8941, 'grad_norm': 18.11685562133789, 'learning_rate': 1.8736212376145077e-05, 'epoch': 0.19}\n",
      "{'loss': 4.7837, 'grad_norm': 16.818357467651367, 'learning_rate': 1.8717517292951954e-05, 'epoch': 0.19}\n",
      "{'loss': 4.766, 'grad_norm': 17.921199798583984, 'learning_rate': 1.8698822209758837e-05, 'epoch': 0.2}\n",
      "{'loss': 4.8012, 'grad_norm': 18.079927444458008, 'learning_rate': 1.8680127126565714e-05, 'epoch': 0.2}\n",
      "{'loss': 4.9297, 'grad_norm': 16.753686904907227, 'learning_rate': 1.8661432043372595e-05, 'epoch': 0.2}\n",
      "{'loss': 4.8018, 'grad_norm': 18.35965919494629, 'learning_rate': 1.8642736960179475e-05, 'epoch': 0.2}\n",
      "{'loss': 4.7978, 'grad_norm': 19.15983009338379, 'learning_rate': 1.8624041876986355e-05, 'epoch': 0.21}\n",
      "{'loss': 4.7684, 'grad_norm': 17.321855545043945, 'learning_rate': 1.8605346793793232e-05, 'epoch': 0.21}\n",
      "{'loss': 4.739, 'grad_norm': 17.48865509033203, 'learning_rate': 1.8586651710600116e-05, 'epoch': 0.21}\n",
      "{'loss': 4.801, 'grad_norm': 15.945019721984863, 'learning_rate': 1.8567956627406993e-05, 'epoch': 0.22}\n",
      "{'loss': 4.7436, 'grad_norm': 19.076091766357422, 'learning_rate': 1.8549261544213873e-05, 'epoch': 0.22}\n",
      "{'loss': 4.7147, 'grad_norm': 18.0029354095459, 'learning_rate': 1.8530566461020753e-05, 'epoch': 0.22}\n",
      "{'loss': 4.7988, 'grad_norm': 18.106536865234375, 'learning_rate': 1.8511871377827634e-05, 'epoch': 0.22}\n",
      "{'loss': 4.7111, 'grad_norm': 16.847803115844727, 'learning_rate': 1.849317629463451e-05, 'epoch': 0.23}\n",
      "{'loss': 4.7768, 'grad_norm': 16.10255241394043, 'learning_rate': 1.8474481211441394e-05, 'epoch': 0.23}\n",
      "{'loss': 4.7729, 'grad_norm': 17.220659255981445, 'learning_rate': 1.845578612824827e-05, 'epoch': 0.23}\n",
      "{'loss': 4.6231, 'grad_norm': 16.761123657226562, 'learning_rate': 1.843709104505515e-05, 'epoch': 0.24}\n",
      "{'loss': 4.6904, 'grad_norm': 16.161365509033203, 'learning_rate': 1.8418395961862032e-05, 'epoch': 0.24}\n",
      "{'loss': 4.732, 'grad_norm': 16.29410743713379, 'learning_rate': 1.8399700878668912e-05, 'epoch': 0.24}\n",
      "{'loss': 4.6707, 'grad_norm': 15.08283805847168, 'learning_rate': 1.838100579547579e-05, 'epoch': 0.24}\n",
      "{'loss': 4.6903, 'grad_norm': 17.40087127685547, 'learning_rate': 1.8362310712282673e-05, 'epoch': 0.25}\n",
      "{'loss': 4.719, 'grad_norm': 17.391225814819336, 'learning_rate': 1.834361562908955e-05, 'epoch': 0.25}\n",
      "{'loss': 4.6557, 'grad_norm': 15.920068740844727, 'learning_rate': 1.832492054589643e-05, 'epoch': 0.25}\n",
      "{'loss': 4.6462, 'grad_norm': 18.35546112060547, 'learning_rate': 1.830622546270331e-05, 'epoch': 0.26}\n",
      "{'loss': 4.5444, 'grad_norm': 16.273967742919922, 'learning_rate': 1.828753037951019e-05, 'epoch': 0.26}\n",
      "{'loss': 4.5692, 'grad_norm': 16.387954711914062, 'learning_rate': 1.826883529631707e-05, 'epoch': 0.26}\n",
      "{'loss': 4.538, 'grad_norm': 14.877020835876465, 'learning_rate': 1.825014021312395e-05, 'epoch': 0.26}\n",
      "{'loss': 4.6529, 'grad_norm': 15.904709815979004, 'learning_rate': 1.823144512993083e-05, 'epoch': 0.27}\n",
      "{'loss': 4.607, 'grad_norm': 16.42275047302246, 'learning_rate': 1.8212750046737712e-05, 'epoch': 0.27}\n",
      "{'loss': 4.567, 'grad_norm': 15.091334342956543, 'learning_rate': 1.819405496354459e-05, 'epoch': 0.27}\n",
      "{'loss': 4.5939, 'grad_norm': 16.6328125, 'learning_rate': 1.817535988035147e-05, 'epoch': 0.27}\n",
      "{'loss': 4.523, 'grad_norm': 16.059057235717773, 'learning_rate': 1.815666479715835e-05, 'epoch': 0.28}\n",
      "{'loss': 4.6698, 'grad_norm': 16.10379981994629, 'learning_rate': 1.813796971396523e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ardav\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "C:\\Users\\ardav\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5802, 'grad_norm': 14.812601089477539, 'learning_rate': 1.8119274630772107e-05, 'epoch': 0.28}\n",
      "{'loss': 4.5719, 'grad_norm': 15.016016960144043, 'learning_rate': 1.810057954757899e-05, 'epoch': 0.29}\n",
      "{'loss': 4.6157, 'grad_norm': 15.794541358947754, 'learning_rate': 1.8081884464385868e-05, 'epoch': 0.29}\n",
      "{'loss': 4.5529, 'grad_norm': 15.16984748840332, 'learning_rate': 1.8063189381192748e-05, 'epoch': 0.29}\n",
      "{'loss': 4.4221, 'grad_norm': 15.928583145141602, 'learning_rate': 1.8044494297999628e-05, 'epoch': 0.29}\n",
      "{'loss': 4.6096, 'grad_norm': 14.532090187072754, 'learning_rate': 1.802579921480651e-05, 'epoch': 0.3}\n",
      "{'loss': 4.4084, 'grad_norm': 15.397406578063965, 'learning_rate': 1.8007104131613385e-05, 'epoch': 0.3}\n",
      "{'loss': 4.3625, 'grad_norm': 16.274179458618164, 'learning_rate': 1.798840904842027e-05, 'epoch': 0.3}\n",
      "{'loss': 4.5624, 'grad_norm': 15.050015449523926, 'learning_rate': 1.7969713965227146e-05, 'epoch': 0.31}\n",
      "{'loss': 4.3743, 'grad_norm': 14.865405082702637, 'learning_rate': 1.7951018882034026e-05, 'epoch': 0.31}\n",
      "{'loss': 4.3513, 'grad_norm': 15.471636772155762, 'learning_rate': 1.7932323798840907e-05, 'epoch': 0.31}\n",
      "{'loss': 4.6243, 'grad_norm': 15.67629337310791, 'learning_rate': 1.7913628715647787e-05, 'epoch': 0.31}\n",
      "{'loss': 4.5477, 'grad_norm': 13.328303337097168, 'learning_rate': 1.7894933632454664e-05, 'epoch': 0.32}\n",
      "{'loss': 4.4197, 'grad_norm': 15.585408210754395, 'learning_rate': 1.7876238549261548e-05, 'epoch': 0.32}\n",
      "{'loss': 4.4706, 'grad_norm': 14.989717483520508, 'learning_rate': 1.7857543466068425e-05, 'epoch': 0.32}\n",
      "{'loss': 4.3446, 'grad_norm': 15.164494514465332, 'learning_rate': 1.7838848382875305e-05, 'epoch': 0.33}\n",
      "{'loss': 4.4893, 'grad_norm': 16.19986343383789, 'learning_rate': 1.7820153299682185e-05, 'epoch': 0.33}\n",
      "{'loss': 4.3583, 'grad_norm': 15.40443229675293, 'learning_rate': 1.7801458216489066e-05, 'epoch': 0.33}\n",
      "{'loss': 4.5494, 'grad_norm': 14.585331916809082, 'learning_rate': 1.7782763133295943e-05, 'epoch': 0.33}\n",
      "{'loss': 4.3054, 'grad_norm': 14.840690612792969, 'learning_rate': 1.7764068050102826e-05, 'epoch': 0.34}\n",
      "{'loss': 4.2197, 'grad_norm': 15.27968692779541, 'learning_rate': 1.7745372966909703e-05, 'epoch': 0.34}\n",
      "{'loss': 4.3346, 'grad_norm': 16.418376922607422, 'learning_rate': 1.7726677883716583e-05, 'epoch': 0.34}\n",
      "{'loss': 4.314, 'grad_norm': 15.027669906616211, 'learning_rate': 1.7707982800523464e-05, 'epoch': 0.34}\n",
      "{'loss': 4.3561, 'grad_norm': 15.437600135803223, 'learning_rate': 1.7689287717330344e-05, 'epoch': 0.35}\n",
      "{'loss': 4.4227, 'grad_norm': 14.671870231628418, 'learning_rate': 1.767059263413722e-05, 'epoch': 0.35}\n",
      "{'loss': 4.5459, 'grad_norm': 15.7618408203125, 'learning_rate': 1.7651897550944105e-05, 'epoch': 0.35}\n",
      "{'loss': 4.4537, 'grad_norm': 15.982333183288574, 'learning_rate': 1.763320246775098e-05, 'epoch': 0.36}\n",
      "{'loss': 4.3314, 'grad_norm': 13.646997451782227, 'learning_rate': 1.7614507384557862e-05, 'epoch': 0.36}\n",
      "{'loss': 4.2926, 'grad_norm': 14.033495903015137, 'learning_rate': 1.7595812301364742e-05, 'epoch': 0.36}\n",
      "{'loss': 4.2548, 'grad_norm': 15.09887409210205, 'learning_rate': 1.7577117218171623e-05, 'epoch': 0.36}\n",
      "{'loss': 4.3541, 'grad_norm': 14.634133338928223, 'learning_rate': 1.75584221349785e-05, 'epoch': 0.37}\n",
      "{'loss': 4.2329, 'grad_norm': 13.977055549621582, 'learning_rate': 1.7539727051785383e-05, 'epoch': 0.37}\n",
      "{'loss': 4.5499, 'grad_norm': 13.603877067565918, 'learning_rate': 1.752103196859226e-05, 'epoch': 0.37}\n",
      "{'loss': 4.2181, 'grad_norm': 14.994195938110352, 'learning_rate': 1.750233688539914e-05, 'epoch': 0.38}\n",
      "{'loss': 4.3245, 'grad_norm': 15.510178565979004, 'learning_rate': 1.748364180220602e-05, 'epoch': 0.38}\n",
      "{'loss': 4.2995, 'grad_norm': 14.207015991210938, 'learning_rate': 1.74649467190129e-05, 'epoch': 0.38}\n",
      "{'loss': 4.2573, 'grad_norm': 14.074817657470703, 'learning_rate': 1.7446251635819778e-05, 'epoch': 0.38}\n",
      "{'loss': 4.2431, 'grad_norm': 14.677518844604492, 'learning_rate': 1.7427556552626662e-05, 'epoch': 0.39}\n",
      "{'loss': 4.3063, 'grad_norm': 13.810751914978027, 'learning_rate': 1.740886146943354e-05, 'epoch': 0.39}\n",
      "{'loss': 4.1356, 'grad_norm': 14.308874130249023, 'learning_rate': 1.739016638624042e-05, 'epoch': 0.39}\n",
      "{'loss': 4.2393, 'grad_norm': 13.215716361999512, 'learning_rate': 1.73714713030473e-05, 'epoch': 0.4}\n",
      "{'loss': 4.2658, 'grad_norm': 13.691533088684082, 'learning_rate': 1.735277621985418e-05, 'epoch': 0.4}\n",
      "{'loss': 4.3422, 'grad_norm': 13.350062370300293, 'learning_rate': 1.733408113666106e-05, 'epoch': 0.4}\n",
      "{'loss': 4.2952, 'grad_norm': 14.753854751586914, 'learning_rate': 1.731538605346794e-05, 'epoch': 0.4}\n",
      "{'loss': 4.2776, 'grad_norm': 13.237956047058105, 'learning_rate': 1.7296690970274817e-05, 'epoch': 0.41}\n",
      "{'loss': 4.2192, 'grad_norm': 13.82628345489502, 'learning_rate': 1.72779958870817e-05, 'epoch': 0.41}\n",
      "{'loss': 4.0954, 'grad_norm': 13.616025924682617, 'learning_rate': 1.7259300803888578e-05, 'epoch': 0.41}\n",
      "{'loss': 4.317, 'grad_norm': 12.779642105102539, 'learning_rate': 1.7240605720695458e-05, 'epoch': 0.42}\n",
      "{'loss': 4.2081, 'grad_norm': 13.085548400878906, 'learning_rate': 1.722191063750234e-05, 'epoch': 0.42}\n",
      "{'loss': 4.1461, 'grad_norm': 13.963549613952637, 'learning_rate': 1.720321555430922e-05, 'epoch': 0.42}\n",
      "{'loss': 4.2234, 'grad_norm': 13.603269577026367, 'learning_rate': 1.7184520471116096e-05, 'epoch': 0.42}\n",
      "{'loss': 4.1394, 'grad_norm': 13.207465171813965, 'learning_rate': 1.716582538792298e-05, 'epoch': 0.43}\n",
      "{'loss': 4.2556, 'grad_norm': 13.4380464553833, 'learning_rate': 1.7147130304729856e-05, 'epoch': 0.43}\n",
      "{'loss': 4.1454, 'grad_norm': 13.266190528869629, 'learning_rate': 1.7128435221536737e-05, 'epoch': 0.43}\n",
      "{'loss': 4.1221, 'grad_norm': 13.28296184539795, 'learning_rate': 1.7109740138343617e-05, 'epoch': 0.43}\n",
      "{'loss': 4.0004, 'grad_norm': 13.559297561645508, 'learning_rate': 1.7091045055150497e-05, 'epoch': 0.44}\n",
      "{'loss': 4.1219, 'grad_norm': 13.063606262207031, 'learning_rate': 1.7072349971957374e-05, 'epoch': 0.44}\n",
      "{'loss': 4.2514, 'grad_norm': 13.999432563781738, 'learning_rate': 1.7053654888764258e-05, 'epoch': 0.44}\n",
      "{'loss': 4.1962, 'grad_norm': 12.632527351379395, 'learning_rate': 1.7034959805571135e-05, 'epoch': 0.45}\n",
      "{'loss': 4.0772, 'grad_norm': 14.040070533752441, 'learning_rate': 1.7016264722378015e-05, 'epoch': 0.45}\n",
      "{'loss': 4.1067, 'grad_norm': 13.907864570617676, 'learning_rate': 1.6997569639184896e-05, 'epoch': 0.45}\n",
      "{'loss': 4.064, 'grad_norm': 12.665233612060547, 'learning_rate': 1.6978874555991776e-05, 'epoch': 0.45}\n",
      "{'loss': 4.1829, 'grad_norm': 13.182123184204102, 'learning_rate': 1.6960179472798656e-05, 'epoch': 0.46}\n",
      "{'loss': 4.1024, 'grad_norm': 13.872933387756348, 'learning_rate': 1.6941484389605537e-05, 'epoch': 0.46}\n",
      "{'loss': 4.0984, 'grad_norm': 13.062402725219727, 'learning_rate': 1.6922789306412414e-05, 'epoch': 0.46}\n",
      "{'loss': 4.2092, 'grad_norm': 12.8549222946167, 'learning_rate': 1.6904094223219294e-05, 'epoch': 0.47}\n",
      "{'loss': 4.2417, 'grad_norm': 12.184584617614746, 'learning_rate': 1.6885399140026174e-05, 'epoch': 0.47}\n",
      "{'loss': 3.9444, 'grad_norm': 12.598721504211426, 'learning_rate': 1.6866704056833054e-05, 'epoch': 0.47}\n",
      "{'loss': 3.9744, 'grad_norm': 13.177312850952148, 'learning_rate': 1.6848008973639935e-05, 'epoch': 0.47}\n",
      "{'loss': 4.0511, 'grad_norm': 13.382756233215332, 'learning_rate': 1.6829313890446815e-05, 'epoch': 0.48}\n",
      "{'loss': 4.1637, 'grad_norm': 12.414631843566895, 'learning_rate': 1.6810618807253692e-05, 'epoch': 0.48}\n",
      "{'loss': 4.1559, 'grad_norm': 13.685674667358398, 'learning_rate': 1.6791923724060572e-05, 'epoch': 0.48}\n",
      "{'loss': 4.1777, 'grad_norm': 12.689118385314941, 'learning_rate': 1.6773228640867453e-05, 'epoch': 0.49}\n",
      "{'loss': 4.0957, 'grad_norm': 13.152653694152832, 'learning_rate': 1.6754533557674333e-05, 'epoch': 0.49}\n",
      "{'loss': 3.9981, 'grad_norm': 13.839308738708496, 'learning_rate': 1.6735838474481213e-05, 'epoch': 0.49}\n",
      "{'loss': 4.1924, 'grad_norm': 13.034375190734863, 'learning_rate': 1.6717143391288094e-05, 'epoch': 0.49}\n",
      "{'loss': 4.1176, 'grad_norm': 12.00395393371582, 'learning_rate': 1.669844830809497e-05, 'epoch': 0.5}\n",
      "{'loss': 4.2413, 'grad_norm': 13.05034351348877, 'learning_rate': 1.667975322490185e-05, 'epoch': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"indobert2gpt-text-summarization\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    save_steps=1000,\n",
    "    fp16=True  # Enable mixed precision if supported for faster training\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=encoder_tokenizer,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('indobert2gpt-text-summarization')\n",
    "tokenizer.save_pretrained('indobert2gpt-text-summarization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
